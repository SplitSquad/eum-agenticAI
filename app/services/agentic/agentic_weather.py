from googleapiclient.discovery import build
from dotenv import load_dotenv
from loguru import logger
from app.core.llm_client import get_llm_client
from app.services.common.user_information import User_Api
import os
import requests
from bs4 import BeautifulSoup
load_dotenv()  # .env íŒŒì¼ì„ ì½ì–´ì„œ í™˜ê²½ë³€ìˆ˜ë¡œ ë“±ë¡

class Weather():
    def __init__(self):
        self.api_key = os.getenv("GOOGLE_SERACH_WEATHER_API_KEY")
        self.search_engine_id = os.getenv("GOOGLE_SEARCH_WEATHER_ENGINE_ID")
        self.user_information = User_Api()

    async def weather_google_search(self, query,token):
        logger.info("[êµ¬ê¸€ ì„œì¹˜ì¤‘...]")
        service = build("customsearch", "v1", developerKey=self.api_key)


        user_information = await self.user_information.user_api(token)
        if user_information.get("address") is None:
            user_information["address"] = "ë¶€ì‚° ë™êµ¬"
    

        # aiê°€ ì¿¼ë¦¬ë¬¸ ë‹¤ë“¬ì–´ì¤Œ.

        # LLM í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
        llm_client = get_llm_client(is_lightweight=False)

        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""
        Extract the region name from the user's input and match it to one of the following values:
        [ì„œìš¸, ë¶€ì‚°, ëŒ€êµ¬, ì¸ì²œ, ê´‘ì£¼, ëŒ€ì „, ìš¸ì‚°, ì„¸ì¢…, ê²½ê¸°ë„, ê°•ì›ë„, ì¶©ì²­ë¶ë„, ì¶©ì²­ë‚¨ë„, ì „ë¼ë¶ë„, ì „ë¼ë‚¨ë„, ê²½ìƒë¶ë„, ê²½ìƒë‚¨ë„, ì œì£¼ë„]

        1. If the user's input contains a region, return the matching region name.
        2. If no region is found, use the user's address information <{user_information['address']}> to determine the most appropriate region.
        3. PRIORTIZE FIRST INSTRUCTION.
        4. RESPONSE MUST BE VALUE, NOT NATURAL LANGUAGE.

        """

        # ì§ì ‘ í˜¸ì¶œ (í´ë¼ì´ì–¸íŠ¸ë§ˆë‹¤ ë°©ì‹ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
        response_query = await llm_client.generate(prompt)
        logger.info(f"[aiê°€ ê²€ìƒ‰í•  ë¬¸ì¥] : {response_query}")

        text = response_query

        url = await self.get_special_weather_url(text)
        logger.info(f"[aiê°€ ê²€ìƒ‰í•  url] : {url}")

        response = requests.get(url, headers={"User-Agent": "Mozilla/5.0"})
        soup = BeautifulSoup(response.text, "html.parser")

        print(f"[soup] : {soup}")
        
        # í¬ë¡¤ë§
        if not url:
            return {"response": "ê¸°ìƒì²­ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.", "url": None}

        html_data = await self.Crawling(url)
        return {
            "response": html_data,
            "metadata": {
                "source": "kma.go.kr",
                "state": "parsed",
                "results": "html"
            },
            "url": url
        }

    async def Crawling(self, url: str, city_name: str = "ë¶€ì‚°"):
        logger.info(f"[HTML í¬ë¡¤ë§ ì¤‘] : {url}")
        try:
            headers = {"User-Agent": "Mozilla/5.0"}
            response = requests.get(url, headers=headers)
            if response.status_code != 200:
                return "í˜ì´ì§€ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

            soup = BeautifulSoup(response.text, "html.parser")

            # âœ… 1. ë‚ ì§œ í—¤ë” ì¶”ì¶œ
            table = soup.select_one("table.table_midterm")
            if not table:
                return "ë‚ ì”¨ í…Œì´ë¸”ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

            headers = [th.text.strip() for th in table.select("thead tr th")[2:]]

            # âœ… 2. 'ë¶€ì‚°'ì´ í¬í•¨ëœ í–‰ ì°¾ê¸°
            for row in table.select("tbody tr"):
                ths = row.find_all("th")
                if len(ths) >= 2 and city_name == ths[1].text.strip():
                    tds = row.find_all("td")
                    forecast = []

                    for i in range(min(len(headers), len(tds))):
                        td = tds[i]
                        weather_img = td.find("img")
                        weather = weather_img["alt"] if weather_img else "ì •ë³´ ì—†ìŒ"

                        spans = td.find_all("span")
                        if len(spans) >= 2:
                            low = spans[0].text.strip()
                            high = spans[1].text.strip()
                            forecast.append(f"ğŸ—“ï¸ {headers[i]}: {weather}, {low}â„ƒ / {high}â„ƒ")
                        else:
                            forecast.append(f"ğŸ—“ï¸ {headers[i]}: {weather}, ì •ë³´ ì—†ìŒ")

                    return f"ğŸ“ {city_name} ë‚ ì”¨ ì •ë³´\n" + "\n".join(forecast)

            return f"{city_name} ì§€ì—­ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        except Exception as e:
            logger.exception("í¬ë¡¤ë§ ì‹¤íŒ¨")
            return f"í¬ë¡¤ë§ ì˜¤ë¥˜: {e}"



    async def get_special_weather_url(self,area_name: str) -> str:
        AREA_CODE_MAP = {
            "ì„œìš¸": {
                "sido": "1100000000",
                "gugun": "2644000000",
                "dong": "2644058000"
            },
            "ë¶€ì‚°": {
                "sido": "2600000000",
                "gugun": "3023000000",
                "dong": "3023052000"
            },
            "ëŒ€êµ¬": {
                "sido": "2700000000",
                "gugun": "2920000000",
                "dong": "2920054000"
            },
            "ì¸ì²œ": {
                "sido": "2800000000",
                "gugun": "3114000000",
                "dong": "3114056000"
            },
            "ê´‘ì£¼": {
                "sido": "2900000000",
                "gugun": "4729000000",
                "dong": "4729053000"
            },
            "ëŒ€ì „": {
                "sido": "3000000000",
                "gugun": "2720000000",
                "dong": "2720065000"
            },
            "ìš¸ì‚°": {
                "sido": "3100000000",
                "gugun": "3611000000",
                "dong": "3611055000"
            },
            "ì„¸ì¢…": {
                "sido": "3600000000",
                "gugun": "1168000000",
                "dong": "1168066000"
            },
            "ê²½ê¸°ë„": {
                "sido": "4100000000",
                "gugun": "4215000000",
                "dong": "4215061500"
            },
            "ê°•ì›ë„": {
                "sido": "4200000000",
                "gugun": "4182000000",
                "dong": "4182025000"
            },
            "ì¶©ì²­ë¶ë„": {
                "sido": "4400000000",
                "gugun": "5013000000",
                "dong": "5013025300"
            },
            "ì¶©ì²­ë‚¨ë„": {
                "sido": "4400000000",
                "gugun": "5013000000",
                "dong": "5013025300"
            },
            "ì „ë¼ë¶ë„": {
                "sido": "4500000000",
                "gugun": "4681000000",
                "dong": "4681025000"
            },
            "ì „ë¼ë‚¨ë„": {
                "sido": "4600000000",
                "gugun": "2871000000",
                "dong": "2871025000"
            },
            "ê²½ìƒë¶ë„": {
                "sido": "4700000000",
                "gugun": "4831000000",
                "dong": "4831034000"
            },
            "ê²½ìƒë‚¨ë„": {
                "sido": "4800000000",
                "gugun": "4182000000",
                "dong": "4182025000"
            },
            "ì œì£¼ë„": {
                "sido": "5000000000",
                "gugun": "4579000000",
                "dong": "4579031000"
            }
        }

        area_name = area_name.strip()

        if area_name in AREA_CODE_MAP:
            code = AREA_CODE_MAP[area_name]
            return f"http://www.weather.go.kr/weather/special/special_03_final.jsp?sido={code['sido']}&gugun={code['gugun']}&dong={code['dong']}"
        else:
            raise ValueError(f"'{area_name}' ì§€ì—­ì€ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
