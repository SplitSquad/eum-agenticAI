from googleapiclient.discovery import build
from dotenv import load_dotenv
from loguru import logger
from app.core.llm_client import get_llm_client
from app.services.common.user_information import User_Api
import os
import requests
from bs4 import BeautifulSoup
load_dotenv()  # .env íŒŒì¼ì„ ì½ì–´ì„œ í™˜ê²½ë³€ìˆ˜ë¡œ ë“±ë¡

class Weather():
    def __init__(self):
        self.api_key = os.getenv("GOOGLE_SERACH_WEATHER_API_KEY")
        self.search_engine_id = os.getenv("GOOGLE_SEARCH_WEATHER_ENGINE_ID")
        self.user_information = User_Api()

    async def weather_google_search(self, query,token):
        logger.info("[êµ¬ê¸€ ì„œì¹˜ì¤‘...]")
        service = build("customsearch", "v1", developerKey=self.api_key)


        user_information = await self.user_information.user_api(token)
        if user_information.get("address") is None:
            user_information["address"] = "ì„œìš¸ ê°•ë‚¨"
    

        # aiê°€ ì¿¼ë¦¬ë¬¸ ë‹¤ë“¬ì–´ì¤Œ.

        # LLM í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
        llm_client = get_llm_client(is_lightweight=False)

        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""
        You are an AI assistant that extracts the location from a user's question in order to generate a weather-related search query.

        ğŸ¯ Your task is as follows:
        1. If the user's input contains a location (city, region, etc.), use it.
        2. If there is no location mentioned, use the default location: "{user_information["address"]}".
        3. The output must follow this exact format:
        ğŸ‘‰ <location> weather (e.g., Seoul weather, Daejeon weather)

        ğŸš« Do NOT explain anything.  
        ğŸš« Do NOT include quotes or additional text.  
        âœ… Output ONLY the final search query, in a single line.

        ---

        [Examples]
        User input: "What's the weather like in Daejeon?"  
        Output: Daejeon weather

        User input: "How's the weather today?"  
        Output: {user_information["address"]} weather

        User input: "Tell me the temperature in Seoul"  
        Output: Seoul weather

        User input: "Is it going to rain?"  
        Output: {user_information["address"]} weather

        ---

        Now convert the following user input into a weather search query:
        {query}
        """

        # ì§ì ‘ í˜¸ì¶œ (í´ë¼ì´ì–¸íŠ¸ë§ˆë‹¤ ë°©ì‹ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
        # response_query = await llm_client.generate(prompt)
        # logger.info(f"[aiê°€ ê²€ìƒ‰í•  ë¬¸ì¥] : {response_query}")

        res = service.cse().list(
            q="ì„œìš¸ ë‚ ì”¨",
            cx=self.search_engine_id,
            num=3,
            dateRestrict='d1',
            siteSearch='kma.go.kr'  # ê¸°ìƒì²­ìœ¼ë¡œ ë„ë©”ì¸ ì œí•œ
        ).execute()

        logger.info(f"[êµ¬ê¸€ ì„œì¹˜ê²°ê³¼] : {res}")

        # ê¸°ìƒì²­ url ì ‘ì†
        url = await self.Meteorological_Administration(res)
        # table = soup.select_one("table.table-col")  # í…Œì´ë¸” í´ë˜ìŠ¤ëª… í™•ì¸ í•„ìš”
        
        # í¬ë¡¤ë§
        if not url:
            return {"response": "ê¸°ìƒì²­ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.", "url": None}

        html_data = await self.Crawling(url)
        return {
            "response": html_data,
            "metadata": {
                "source": "kma.go.kr",
                "state": "parsed",
                "results": "html"
            },
            "url": url
        }

    
    async def Meteorological_Administration(self, res):
        logger.info("[ê¸°ìƒì²­ URL ì¶”ì¶œ ì¤‘...]")
        for item in res.get("items", []):
            link = item.get("link", "")
            if "kma.go.kr" in link:
                logger.info(f"[ê¸°ìƒì²­ URL ì°¾ìŒ] : {link}")
                return link
        logger.warning("ê¸°ìƒì²­ URLì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return None

    async def Crawling(self, url):
        logger.info(f"[HTML í¬ë¡¤ë§ ì¤‘] : {url}")
        try:
            headers = {"User-Agent": "Mozilla/5.0"}
            response = requests.get(url, headers=headers)
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, "html.parser")

                # âœ… í…Œì´ë¸” ì„ íƒ
                table = soup.select_one("table.table-col")  # class í™•ì¸ í•„ìš”

                if not table:
                    return "í…Œì´ë¸”ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

                # âœ… íŠ¹ì • ì§€ì—­(ì˜ˆ: ì„œìš¸)ì˜ ë‚ ì”¨ ì •ë³´ ì¶”ì¶œ
                rows = table.find_all("tr")
                for row in rows:
                    city = row.find("th")
                    if city and "ì„œìš¸" in city.text:
                        cells = row.find_all("td")
                        weather = cells[0].text.strip()
                        temperature = cells[4].text.strip()  # í˜„ì¬ê¸°ì˜¨ (ë³´í†µ 5ë²ˆì§¸ <td>)
                        humidity = cells[8].text.strip()    # ìŠµë„
                        wind_dir = cells[9].text.strip()    # í’í–¥
                        wind_speed = "1.2 m/s"  # JSë¡œ ë Œë”ë§ë˜ì–´ ìˆì–´ ìˆ˜ë™ìœ¼ë¡œ ë„£ê±°ë‚˜ ë¬´ì‹œ

                        return f"ğŸ“ ì„œìš¸\në‚ ì”¨: {weather}\nê¸°ì˜¨: {temperature}â„ƒ\nìŠµë„: {humidity}%\ní’í–¥: {wind_dir}\ní’ì†: {wind_speed}"

                return "ì„œìš¸ ì§€ì—­ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            else:
                logger.error(f"ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
                return "í˜ì´ì§€ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        except Exception as e:
            logger.exception("í¬ë¡¤ë§ ì‹¤íŒ¨")
            return f"í¬ë¡¤ë§ ì˜¤ë¥˜: {e}"



